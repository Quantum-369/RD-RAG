Hey, I just got some idea of improving the RAG pipeline, so basically listen to my thing, so initially we get the user query, so from that user query we just use the rationales, like using the LLM, define the rationales, and from that rationales we get the subqueries, like three or four subqueries, and using these subqueries for each individual query, we retrieve the top N relevant documents using the BM 25 or cosine similarity, so after getting these documents and these subqueries, and these subqueries and these documents will be passed to the cross encoders, then using these cross encoders we will get again re-ranked results, and these re-ranked results are, I mean most from the top K will be sent to the LLM for the context, and then to the user.